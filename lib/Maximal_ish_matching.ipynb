{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def maximal_ish_matching(G,num_matches=10,tol=0.1,max_remove_nodes=1):\n",
    "    '''\n",
    "    Function that finds approximately maximal matchings by removing nodes and using the built-in networkx function\n",
    "    \n",
    "    Input:\n",
    "        G - undirected, bipartite network\n",
    "            Note: the nodes should be indexed by integer\n",
    "        num_matches - number of unique matches to return\n",
    "        tol - percentage of nodes that can be dropped from the maximal matching \n",
    "            (e.g. if tol=0.1, then the returned maximal matchings can be up to 10% smaller than a full maximal matching)\n",
    "        max_remove_nodes - the number of nodes that can be removed from the graph to search for matchings\n",
    "            \n",
    "    Output:\n",
    "        all_matches - a list of dictionaries\n",
    "    '''\n",
    "    \n",
    "    #The first matching is easy, and always maximal\n",
    "    all_matches = []\n",
    "    all_matches.append(nx.bipartite.hopcroft_karp_matching(G))\n",
    "    \n",
    "    #Get the number of nodes corresponding to the tolerance\n",
    "    tol_num = int((1-tol)*len(all_matches[0]))\n",
    "\n",
    "    \n",
    "    #Loop through and remove nodes one by one until we get enough unique matchings\n",
    "    min_node = min(G.nodes())\n",
    "    max_node= max(G.nodes())\n",
    "    node_list = range(min_node,max_node)\n",
    "    \n",
    "    this_node = 0\n",
    "    this_remove_nodes = 1\n",
    "    \n",
    "    while True:\n",
    "        G2 = G.copy()\n",
    "        G2.remove_node(node_list[0])\n",
    "        thismatch = nx.bipartite.hopcroft_karp_matching(G2)\n",
    "        #Check if this is valid\n",
    "        if (len(thismatch)>tol_num) and (not thismatch in all_matches):\n",
    "            all_matches.append(thismatch)\n",
    "        \n",
    "        this_node+=1\n",
    "            \n",
    "        if len(all_matches)>=num_matches:\n",
    "            break\n",
    "        elif this_node>max_node:\n",
    "            if this_remove_nodes<max_remove_nodes:\n",
    "                #Reset the index (this_node) and create a new list of node pairs to remove\n",
    "                # Note that we want to randomize this list!\n",
    "                this_remove_nodes+=1\n",
    "                from itertools import combinations\n",
    "                import random\n",
    "                SEED = 4242\n",
    "                random.seed(SEED)\n",
    "                node_list = combinations(range(min_node,max_node),this_remove_nodes)\n",
    "                node_list = shuffle(node_list)\n",
    "                this_node = 0\n",
    "            else:\n",
    "                import warnings\n",
    "                warnings.warn(\"All nodes cycled through without reaching enough unique cycles; halting and returning all found\")\n",
    "                break\n",
    "    \n",
    "    \n",
    "    return all_matches"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
